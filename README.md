

# âœ¨ DeCo-Diff âœ¨
**A PyTorch Implementation for Multi-Class Unsupervised Anomaly Detection**

This repository hosts the official PyTorch implementation for our CVPR 2025 paper:  
**"Correcting Deviations from Normality: A Reformulated Diffusion Model for Unsupervised Anomaly Detection"**.

---

## ğŸ¨ Approach


![DeCo-Diff](./assets/DeCo-for-UAD.png)

---

## ğŸš€ Getting Started

### ğŸ› ï¸ Environment Setup

We utilize **Python 3.11** for all experiments. To install the necessary packages, simply run:

```bash
pip3 install -r requirements.txt
```

### ğŸ“ Datasets

Download the datasets below and organize them as shown:
- [MVTec-AD](https://www.mvtec.com/company/research/datasets/mvtec-ad)
- [VisA](https://amazon-visual-anomaly.s3.us-west-2.amazonaws.com/VisA_20220922.tar)

The expected file structure (default for MVTec-AD) is as follows:
```
â”œâ”€â”€ class1
â”‚   â”œâ”€â”€ ground_truth
â”‚   â”‚   â”œâ”€â”€ defect1
â”‚   â”‚   â””â”€â”€ defect2
â”‚   â”œâ”€â”€ test
â”‚   â”‚   â”œâ”€â”€ defect1
â”‚   â”‚   â”œâ”€â”€ defect2
â”‚   â”‚   â””â”€â”€ good
â”‚   â””â”€â”€ train
â”‚       â””â”€â”€ good
â”œâ”€â”€ class2
...
```

---

## ğŸ‹ï¸ Training

Train our model using the following command. This command sets up the RLR training with various options tailored to your dataset and desired augmentations:

```bash
torchrun evaluation_DeCo_Diff.py \
            --dataset mvtec \
            --data-dir ./mvtec-dataset/ \
            --model-size UNet_L \
            --mask-random-ratio True \
            --object-category all  \
            --image-size 288 \
            --center-size 256 \
            --center-crop True \
            --augmentation True \
            --ckpt-every 20 
```

---

## ğŸ§ª Testing

Once the model is trained, test its performance using the command below:

```bash
python evaluation_DeCo_Diff.py \
            --dataset mvtec \
            --data-dir ./mvtec-dataset/ \
            --model-size UNet_L \
            --object-category all  \
            --anomaly-class all  \
            --image-size 288 \
            --center-size 256 \
            --center-crop True \
            --pretrained /path/to/pretrained_weights.pt
```
---

## ğŸ“¦ Pretrained Weights

For convenience, we provide pretrained weights for DeCo-Diff. These weights can be used for rapid inference and further experimentation:

- **MVTec-AD Pretrained Weights:**  
  Download from [Google Drive](https://drive.google.com/file/d/1kWXXao57CzLDmatePAmMoTZG5YZsrVRl/view?usp=share_link) 
  
- **VisA Pretrained Weights:**  
  Download from [Google Drive](https://drive.google.com/file/d/1uNE-Vtb7TPeuMkyepTbKFsxUy8472enx/view?usp=share_link) 

---

## ğŸ“Š Results

Below are the performances of DeCo-Diff on the MVTec-AD and VisA datasets. These results illustrate the high efficacy of DeCo-Diff in detecting anomalies in multi-class UAD setting.


|**Dataset**  |I-**AUROC**| I-**AP** |I-**f1max**|P-**AUROC**| P-**AP** |P-**f1max**|P-**AUPRO**|
|-------------|-----------|----------|-----------|-----------|--------|-----------|-----------|
| MVTec-AD   |    99.3    |   99.8   |   98.5    |   98.4    |  74.9  |   69.7    |   94.9    |
| VisA       |    96.4    |   96.8   |   92.2    |   98.5    |  51.3  |   51.2    |   92.1    |

---

## ğŸ“¸ Sample Results

Below are some sample outputs showcasing the performance of DeCo-Diff on real data:

![DeCo-Diff Samples](./assets/Samples.png)

---





